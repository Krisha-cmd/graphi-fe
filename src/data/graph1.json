{
  "nodes": [
    { "id": "1", "title": "Attention Is All You Need", "authors": "Vaswani et al.", "year": 2017, "citations": 89341, "category": "Deep Learning" },
    { "id": "2", "title": "BERT: Pre-training of Deep Bidirectional Transformers", "authors": "Devlin et al.", "year": 2019, "citations": 42156, "category": "NLP" },
    { "id": "3", "title": "Language Models are Few-Shot Learners", "authors": "Brown et al.", "year": 2020, "citations": 28934, "category": "NLP" },
    { "id": "4", "title": "RoBERTa: A Robustly Optimized BERT Pretraining Approach", "authors": "Liu et al.", "year": 2019, "citations": 15678, "category": "NLP" },
    { "id": "5", "title": "Exploring the Limits of Transfer Learning", "authors": "Raffel et al.", "year": 2020, "citations": 12456, "category": "NLP" },
    { "id": "6", "title": "GPT-3 Applications in Natural Language Processing", "authors": "Smith et al.", "year": 2021, "citations": 8934, "category": "NLP" }
  ],
  "edges": [
    { "source": "2", "target": "1", "relation": "cited-by" },
    { "source": "3", "target": "1", "relation": "cited-by" },
    { "source": "4", "target": "2", "relation": "cited-by" },
    { "source": "5", "target": "1", "relation": "cited-by" },
    { "source": "6", "target": "3", "relation": "cited-by" },
    { "source": "3", "target": "2", "relation": "cited-by" }
  ]
}